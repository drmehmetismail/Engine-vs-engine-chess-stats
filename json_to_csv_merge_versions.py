"""This script inputs the JSON file generated by lichess_evals_extractor.py and outputs a CSV file
 merging all versions of the same engine. It also merges engines with  different version names 
 (e.g. Stockfish and asmFish).
"""

import json
import os
import pandas as pd
import glob
import time

def extract_first_word(full_name):
    return full_name.split()[0] if full_name else ''

def process_single_json_file(json_file_path):
    data_list = []
    with open(json_file_path, 'r') as f:
        all_data = json.load(f)
        if not all_data:
            print(f"No data found in {json_file_path}")
            return pd.DataFrame()
        for key, data in all_data.items():
            white_player = data.get('White', '')
            black_player = data.get('Black', '')

            data['White'] = extract_first_word(white_player)
            data['Black'] = extract_first_word(black_player)
            
            flattened_data = pd.json_normalize(data)
            data_list.append(flattened_data)
    return pd.concat(data_list, ignore_index=True)

def process_json_files(json_dir_path, csv_output_dir):
    all_files = glob.glob(os.path.join(json_dir_path, '**/*.json'), recursive=True)
    aggregated_data = pd.DataFrame()

    for json_file in all_files:
        try:
            df = process_single_json_file(json_file)
            aggregated_data = pd.concat([aggregated_data, df], ignore_index=True)
        except Exception as e:
            print(f'Error processing {json_file}: {e}')

    if not aggregated_data.empty:
        csv_output_file = os.path.join(csv_output_dir, 'engine_aggregated_game_data_merged_engines.csv')
        if not os.path.exists(csv_output_dir):
            os.makedirs(csv_output_dir)
        aggregated_data.to_csv(csv_output_file, index=False)
        print(f"Data saved to {csv_output_file}")
    else:
        print("No data to save.")
    return csv_output_file

def replace_engine_names(csv_file_path):
    # Mapping of strings to be replaced with their new values
    replacements = {
        "Stockfish": ["MateFinder", "asmFish", "SugaR", "ShashChess", "Fat"],
        "Komodo": ["Dragon", "Doch"],
        "Zappa": ["Zap!Chess"],
        "Bouquet": ["DeepSaros", "Elektro", "IvanHoe", "RobboLito"]
    }

    # Read the CSV file
    df = pd.read_csv(csv_file_path)

    # Check if the specified columns exist in the DataFrame
    target_columns = ['Black', 'White']
    for col in target_columns:
        if col in df.columns:
            for new_value, old_values in replacements.items():
                for old_value in old_values:
                    df[col] = df[col].replace(old_value, new_value)

    # Save the modified DataFrame back to the CSV
    df.to_csv(csv_file_path, index=False)

    print(f"File '{csv_file_path}' updated successfully.")

def main(json_dir, csv_output_dir):
    csv_output_file = process_json_files(json_dir, csv_output_dir)
    replace_engine_names(csv_output_file)

if __name__ == "__main__":
    if len(sys.argv) < 3:
        print("Usage: python json_to_csv_converter.py <json_file_path> <csv_output_dir>")
        sys.exit(1)

    json_dir = sys.argv[1]
    csv_output_dir = sys.argv[2]
    main(json_dir, csv_output_dir)
